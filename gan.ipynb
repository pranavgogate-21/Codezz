{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN and DCGAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n",
      "cuda:0\n",
      "1.mnist digit\n",
      "2.mnist fashion\n",
      "3.anime faces\n",
      "4.celbrity face\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    " \n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # This will generate a random seed\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    " \n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "print(device)\n",
    "print(\"1.mnist digit\\n2.mnist fashion\\n3.anime faces\\n4.celbrity face\\n\")\n",
    "n=int(input(\"enter your choice:\"))\n",
    "while(n>4 or n<1):\n",
    "    print(\"enter a valid choice:\")\n",
    "    n=int(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(n==1):\n",
    "    batch_size = 500\n",
    "    epochs = 50000\n",
    "    noise_dim = 100\n",
    "    (train_images, train_labels), (_, _) = keras.datasets.mnist.load_data()\n",
    "    #(train_images, train_labels), (_, _) = keras.datasets.cifar10.load_data()\n",
    "    #(train_images, train_labels), (_, _) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "    train_images = train_images[:batch_size].reshape(batch_size, 28, 28, 1).astype('float32')\n",
    "    train_images = (train_images - 127.5) / 127.5\n",
    "elif(n==2):\n",
    "    batch_size = 500\n",
    "    epochs = 50000\n",
    "    noise_dim = 100\n",
    "    #(train_images, train_labels), (_, _) = keras.datasets.mnist.load_data()\n",
    "    #(train_images, train_labels), (_, _) = keras.datasets.cifar10.load_data()\n",
    "    (train_images, train_labels), (_, _) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "    train_images = train_images[:batch_size].reshape(batch_size, 28, 28, 1).astype('float32')\n",
    "    train_images = (train_images - 127.5) / 127.5\n",
    "elif(n==3):\n",
    "    transform = transforms.Compose([transforms.Resize(64),\n",
    "                                transforms.CenterCrop(64),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    \n",
    "    # We can use an image folder dataset the way we have it setup.\n",
    "    # Create the dataset\n",
    "    dataset = datasets.ImageFolder(root=\"animages1\",\n",
    "                                transform=transform)\n",
    "    # Create the dataloader\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=32,\n",
    "                                            shuffle=True, num_workers=2)\n",
    "else:\n",
    "    transform = transforms.Compose([transforms.Resize(64),\n",
    "                                transforms.CenterCrop(64),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    \n",
    "    # We can use an image folder dataset the way we have it setup.\n",
    "    # Create the dataset\n",
    "    dataset = datasets.ImageFolder(root=\"exp\",\n",
    "                                transform=transform)\n",
    "    # Create the dataloader\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=32,\n",
    "                                            shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the dataset images\n",
    "def imshow(img):\n",
    "  npimg = img.numpy()\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "  plt.show()\n",
    " \n",
    "# We will take one batch of data and show the distribution of pixels in one sample image\n",
    "if(n<3):\n",
    "  fig, axs = plt.subplots(3, 3, figsize=(5, 5))\n",
    "  axs = axs.flatten()\n",
    "  for i in range(9):  \n",
    "    \n",
    "    axs[i].imshow(train_images[i], cmap='gray')\n",
    "    axs[i].axis('off')\n",
    "  plt.show()\n",
    "     \n",
    "\n",
    "else:\n",
    "  data_iter = iter(data_loader)\n",
    "  images, labels = next(data_iter)\n",
    " \n",
    "  imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating generator model\n",
    "if(n<3):\n",
    "    def make_generator_model():\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Dense(256, input_shape=(100,), use_bias=False))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.LeakyReLU())\n",
    "\n",
    "        model.add(layers.Dense(512, use_bias=False))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.LeakyReLU())\n",
    "\n",
    "        model.add(layers.Dense(784, activation='tanh'))\n",
    "        model.add(layers.Reshape((28, 28, 1)))\n",
    "\n",
    "        return model\n",
    "else:\n",
    "    # Creating a function that will create a normal distribution of weights to the Convolutional layers\n",
    "    def init_normal(m):\n",
    "        classname = m.__class__.__name__\n",
    "    \n",
    "        if classname.find('Conv') != -1:\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    feature_map       = 64\n",
    "    latent_space_size = 100\n",
    "    class Generator(nn.Module):\n",
    "        \n",
    "        def __init__(self):\n",
    "            \n",
    "            super(Generator, self).__init__()\n",
    "            \n",
    "            self.convTranspose1 = nn.ConvTranspose2d( latent_space_size, feature_map * 8, 4, 1, 0, bias=False)\n",
    "            self.convTranspose2 = nn.ConvTranspose2d( feature_map * 8  , feature_map * 4, 4, 2, 1, bias=False)\n",
    "            self.convTranspose3 = nn.ConvTranspose2d( feature_map * 4  , feature_map * 2, 4, 2, 1, bias=False)\n",
    "            self.convTranspose4 = nn.ConvTranspose2d( feature_map * 2  , feature_map * 1, 4, 2, 1, bias=False)\n",
    "            self.convTranspose5 = nn.ConvTranspose2d( feature_map * 1  , 3              , 4, 2, 1, bias=False)\n",
    "    \n",
    "            self.bnorm1 = nn.BatchNorm2d(feature_map * 8)\n",
    "            self.bnorm2 = nn.BatchNorm2d(feature_map * 4)\n",
    "            self.bnorm3 = nn.BatchNorm2d(feature_map * 2)\n",
    "            self.bnorm4 = nn.BatchNorm2d(feature_map * 1)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = self.convTranspose1(x)\n",
    "            x = F.relu(self.bnorm1(x))\n",
    "    \n",
    "            x = self.convTranspose2(x)\n",
    "            x = F.relu(self.bnorm2(x))\n",
    "    \n",
    "            x = self.convTranspose3(x)\n",
    "            x = F.relu(self.bnorm3(x))\n",
    "    \n",
    "            x = self.convTranspose4(x)\n",
    "            x = F.relu(self.bnorm4(x))\n",
    "    \n",
    "            x = self.convTranspose5(x)\n",
    "            x = torch.tanh(x)\n",
    "            return x\n",
    "    \n",
    "    # Create the generator\n",
    "    generator = Generator().to(device)\n",
    "\n",
    "\n",
    "\n",
    "    # Helper function for creating a random latent vector\n",
    "    def generate_latent_vectors_z(N):\n",
    "        z = torch.randn(N, 100, 1, 1, device=device)\n",
    "        return z  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for creating a random latent vector\n",
    "def generate_latent_vectors_z(N):\n",
    "    z = torch.randn(N, 100, 1, 1, device=device)\n",
    "    return z  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random latent space of 100 elements which we will use to transform to an image\n",
    "z = generate_latent_vectors_z(1).to(device)\n",
    "random_noise = generator(z)\n",
    " \n",
    "plt.imshow(random_noise[0].cpu().permute(1, 2, 0).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI\n"
     ]
    }
   ],
   "source": [
    "#creating discriminator model\n",
    "if(n<3):\n",
    "    print(\"HI\")\n",
    "    def make_discriminator_model():\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(512))\n",
    "        model.add(layers.LeakyReLU())\n",
    "        model.add(layers.Dense(256))\n",
    "        model.add(layers.LeakyReLU())\n",
    "        model.add(layers.Dense(1))\n",
    "\n",
    "        return model\n",
    "else:\n",
    "    print(\"Hello\")\n",
    "    class Discriminator(nn.Module):\n",
    "        \n",
    "        def __init__(self):\n",
    "            \n",
    "            super(Discriminator, self).__init__()\n",
    "            \n",
    "            self.conv1 = nn.Conv2d(3              , feature_map    , 4, 2, 1, bias=False)\n",
    "            self.conv2 = nn.Conv2d(feature_map    , feature_map * 2, 4, 2, 1, bias=False)\n",
    "            self.conv3 = nn.Conv2d(feature_map * 2, feature_map * 4, 4, 2, 1, bias=False)\n",
    "            self.conv4 = nn.Conv2d(feature_map * 4, feature_map * 8, 4, 2, 1, bias=False)\n",
    "            self.conv5 = nn.Conv2d(feature_map * 8, 1              , 4, 1, 0, bias=False)\n",
    "    \n",
    "            self.bnorm1 = nn.BatchNorm2d(feature_map*2)\n",
    "            self.bnorm2 = nn.BatchNorm2d(feature_map*4)\n",
    "            self.bnorm3 = nn.BatchNorm2d(feature_map*8)\n",
    "    \n",
    "            self.LeakyReLU = nn.LeakyReLU(0.2, inplace=True)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = F.leaky_relu(self.conv1(x))\n",
    "    \n",
    "            x = self.conv2(x)\n",
    "            x = F.leaky_relu(self.bnorm1(x))\n",
    "    \n",
    "            x = self.conv3(x)\n",
    "            x = F.leaky_relu(self.bnorm2(x))\n",
    "            \n",
    "            x = self.conv4(x)\n",
    "            x = F.leaky_relu(self.bnorm3(x))\n",
    "    \n",
    "            x = self.conv5(x)\n",
    "            x = self.sigmoid(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(n<3):\n",
    "    \n",
    "    # Define the loss functions\n",
    "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "    def discriminator_loss(real_output, fake_output):\n",
    "        real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "        total_loss = real_loss + fake_loss\n",
    "        return total_loss\n",
    "\n",
    "    def generator_loss(fake_output):\n",
    "        return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "    # Define the optimizers\n",
    "    generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "    # Create the GAN model\n",
    "    def make_gan_model(generator, discriminator):\n",
    "        model = keras.Sequential()\n",
    "        1\n",
    "\n",
    "\n",
    "        model.add(generator)\n",
    "        model.add(discriminator)\n",
    "        return model\n",
    "    # Instantiate the models and the GAN model\n",
    "    generator = make_generator_model()\n",
    "    discriminator = make_discriminator_model()\n",
    "    gan_model = make_gan_model(generator, discriminator)\n",
    "    \n",
    "\n",
    "else:\n",
    "    # Initialize BCELoss function\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Models\n",
    "    generator =     Generator().to(device)\n",
    "    discriminator = Discriminator().to(device)\n",
    "    \n",
    "    # Use the modules apply function to recursively apply the initialization\n",
    "    generator.apply(init_normal)\n",
    "    discriminator.apply(init_normal)\n",
    "    \n",
    "    # Optimizers\n",
    "    generator_optimizer     = torch.optim.Adam(generator.parameters(),     lr=0.0002)\n",
    "    discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#loading the model\n",
    "if(n==1):\n",
    "    generator = tf.keras.models.load_model(\"my_generatormnist.h5\")\n",
    "    discriminator = tf.keras.models.load_model(\"my_discriminatormnist.h5\")\n",
    "    gan_model = tf.keras.models.load_model(\"my_ganmodelmnist.h5\")\n",
    "elif(n==2):\n",
    "    generator = tf.keras.models.load_model(\"my_generatorfashion.h5\")\n",
    "    discriminator = tf.keras.models.load_model(\"my_discriminatorfashion.h5\")\n",
    "    gan_model = tf.keras.models.load_model(\"my_ganmodelfashion.h5\")\n",
    "elif(n==3):\n",
    "    generator = Generator()\n",
    "    generator.load_state_dict(torch.load(\"DCGAN_anime_generator.pth\"))\n",
    "    generator.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        generator.cuda()\n",
    "    discriminator = Discriminator()\n",
    "    discriminator.load_state_dict(torch.load(\"DCGAN_anime_discriminator.pth\"))\n",
    "    discriminator.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        discriminator.cuda()\n",
    "        \n",
    "else:\n",
    "    generator = Generator()\n",
    "    generator.load_state_dict(torch.load(\"DCGAN_celeba2_generator.pth\"))\n",
    "    generator.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        generator.cuda()\n",
    "    discriminator = Discriminator()\n",
    "    discriminator.load_state_dict(torch.load(\"DCGAN_celeba2_discriminator.pth\"))\n",
    "    discriminator.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        discriminator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "# Define the training loop\n",
    "if(n<3):\n",
    "    @tf.function\n",
    "    def train_step(images):\n",
    "        noise = tf.random.normal([batch_size, 100])\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            generated_images = generator(noise, training=True)\n",
    "\n",
    "            real_output = discriminator(images, training=True)\n",
    "            fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "            gen_loss = generator_loss(fake_output)\n",
    "            disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    # Train the model\n",
    "    batch_size = 500\n",
    "    epochs = 10\n",
    "    noise_dim = 100\n",
    "\n",
    "    #(train_images, train_labels), (_, _) = keras.datasets.mnist.load_data()\n",
    "    #(train_images, train_labels), (_, _) = keras.datasets.cifar10.load_data()\n",
    "    (train_images, train_labels), (_, _) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "    train_images = train_images[:batch_size].reshape(batch_size, 28, 28, 1).astype('float32')\n",
    "    train_images = (train_images - 127.5) / 127.5\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(train_images.shape[0] // batch_size):\n",
    "            batch_images = train_images[i * batch_size : (i+1) * batch_size]\n",
    "            train_step(batch_images)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}')\n",
    "            noise = tf.random.normal([1, noise_dim])\n",
    "            generated_image = generator(noise, training=False)\n",
    "            generated_image = generated_image.numpy().reshape\n",
    "            \n",
    "    #model.save(\"my_model.h\")\n",
    "\n",
    "else:\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=500,\n",
    "                                            shuffle=True, num_workers=2)\n",
    "    print(\"Starting Training Loop...\")\n",
    "    epochs =1\n",
    "    N_samples = 128\n",
    "        \n",
    "    # For each epoch\n",
    "    for epoch in range(epochs):\n",
    "    # For each batch in the dataloader\n",
    "        for idx, images in enumerate(data_loader):\n",
    "            discriminator.zero_grad()\n",
    "        \n",
    "            if (idx%100 ==0):\n",
    "                print(f\"{epoch}/{epochs} epoch | {idx}/{len(data_loader)} batch \\n\")\n",
    "        \n",
    "            # Generate examples of real data\n",
    "            real_data = images[0].to(device)\n",
    "            real_data_label = torch.ones(real_data.shape[0]).to(device)\n",
    "        \n",
    "            # Training of Discriminator\n",
    "            # Forward pass real batch through discriminator\n",
    "            output = discriminator(real_data).view(-1)\n",
    "            errD_real = criterion(output, real_data_label)\n",
    "            # Calculate gradients for D in backward pass\n",
    "            errD_real.backward()\n",
    "            D_x = output.mean().item()\n",
    "        \n",
    "            # Create fake data with a generator\n",
    "            z = generate_latent_vectors_z(len(real_data)).to(device)\n",
    "            fake_data = generator(z)\n",
    "            fake_data_label = torch.zeros(fake_data.shape[0]).to(device)\n",
    "        \n",
    "            # Forward pass fake data through discriminator\n",
    "            output = discriminator(fake_data.detach()).view(-1)\n",
    "            errD_fake = criterion(output, fake_data_label)\n",
    "            errD_fake.backward()\n",
    "        \n",
    "            # Compute error of D as sum over the fake and the real batches\n",
    "            errD = errD_real + errD_fake\n",
    "            # Update discriminator\n",
    "            discriminator_optimizer.step()\n",
    "        \n",
    "            # Training of Generator\n",
    "            generator.zero_grad()\n",
    "            real_data_label = torch.ones(fake_data.shape[0]).to(device) # fake labels are real for generator cost\n",
    "            output = discriminator(fake_data).view(-1)\n",
    "            errG = criterion(output, real_data_label)\n",
    "            errG.backward()\n",
    "        \n",
    "            # Update Generator\n",
    "            generator_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator.save(\"my_generatorfashion.h5\")\n",
    "#discriminator.save(\"my_discriminatorfashion.h5\")\n",
    "#gan_model.save(\"my_ganmodelfashion.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the models\n",
    "\n",
    "torch.save(generator.state_dict(), 'DCGAN_celeba2_generator.pth')\n",
    "torch.save(discriminator.state_dict(), 'DCGAN_celeba2_discriminator.pth')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(n<3):\n",
    "    # Generate images using the trained generator\n",
    "    num_images_to_generate = 64\n",
    "    noise = tf.random.normal([num_images_to_generate, noise_dim])\n",
    "    generated_images = generator(noise, training=False)\n",
    "\n",
    "    # Plot the generated images\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, axs = plt.subplots(8, 8, figsize=(10, 10))\n",
    "    axs = axs.flatten()\n",
    "    for i in range(num_images_to_generate):\n",
    "        axs[i].imshow(generated_images[i, :, :, 0], cmap='gray')\n",
    "        axs[i].axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    # Assuming the generator generates len(real_data) fake images\n",
    "    z = generate_latent_vectors_z(len(real_data)).to(device)\n",
    "\n",
    "    # Generating fake data (images) using the generator\n",
    "    fake_data = generator(z)\n",
    "\n",
    "    # Determine the number of images generated\n",
    "    num_images_generated = len(fake_data)\n",
    "\n",
    "    # Creating a grid to display the images\n",
    "    rows = 4\n",
    "    cols = min(8, num_images_generated // rows)  # Calculate the number of columns based on the available images\n",
    "\n",
    "    # Create a subplots grid\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(10, 10))\n",
    "\n",
    "    # Plotting each generated image in the grid\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            index = i * cols + j\n",
    "            if index < num_images_generated:  # Check if the index is within bounds\n",
    "                img = fake_data[index].cpu().permute(1, 2, 0).detach().numpy()\n",
    "                axes[i, j].imshow(img)\n",
    "                axes[i, j].axis('off')\n",
    "            else:  # If there are no more images to display, break out of the loop\n",
    "                break\n",
    "    # Displaying the grid of images\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
